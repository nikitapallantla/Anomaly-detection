import pandas as pd
import os
import time
import google.generativeai as genai
from datetime import datetime

# --- CONFIGURATION ---
genai.configure(api_key="YOUR_ACTUAL_API_KEY")
model = genai.GenerativeModel('gemini-1.5-flash')
LOG_DIR = "./logs"
DATASET_FILE = "final_dataset.csv"

def get_llm_verdict(prompt):
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"LLM Error: {str(e)}"

def analyze_multimodal(trace_id, service_name):
    # 1. TRACE AGENT (Analyzes Jaeger Architecture)
    # Checks if services are missing or if loops exist
    trace_prompt = f"Analyze Trace ID {trace_id}. If spans are missing between services, flag as architecture anomaly."
    trace_report = get_llm_verdict(trace_prompt)

    # 2. METRIC AGENT (Analyzes Prometheus-style data)
    # Focuses on CPU/Memory spikes
    metric_prompt = f"Analyze metrics for {service_name}. CPU: 92%, Mem: 85%. Is this a DoS signature?"
    metric_report = get_llm_verdict(metric_prompt)

    # 3. LOG AGENT (Analyzes ACTUAL logs from the file)
    # Reads the JSON logs generated by your app.py
    log_content = ""
    log_path = os.path.join(LOG_DIR, f"{service_name}.log")
    if os.path.exists(log_path):
        with open(log_path, 'r') as f:
            log_content = "".join(f.readlines()[-5:]) # Gets +/- 5 log window
    
    log_prompt = f"Analyze these actual logs for Trace {trace_id}: {log_content}. Look for 'Failed Login' or 'Unauthorized'."
    log_report = get_llm_verdict(log_prompt)

    # 4. SUPERVISOR AGENT (Final Verdict & Accuracy)
    final_prompt = f"""
    You are a Security Lead. Correlate these reports:
    Trace: {trace_report}
    Metrics: {metric_report}
    Logs: {log_report}
    
    Verdict format: [ANOMALY/NORMAL], Accuracy: [0-1], Reason: [Short Text]
    """
    verdict = get_llm_verdict(final_prompt)
    return verdict

def append_to_dataset(trace_id, service_name, verdict_text):
    # This solves Issue #2: Results are now appended to the CSV every time
    new_data = {
        "timestamp": datetime.now(),
        "trace_id": trace_id,
        "service_name": service_name,
        "span_count": 14, # Example: total operations in trace
        "service_count": 7, # Total unique services in architecture
        "llm_verdict": verdict_text
    }
    df = pd.DataFrame([new_data])
    df.to_csv(DATASET_FILE, mode='a', header=not os.path.exists(DATASET_FILE), index=False)

# Example Execution
if __name__ == "__main__":
    print("Starting Multi-Modal Analysis...")
    # This would loop 1500 times based on your generated traffic
    sample_trace = "5a3b92c..." 
    result = analyze_multimodal(sample_trace, "auth-service")
    append_to_dataset(sample_trace, "auth-service", result)
    print(f"Analysis complete for {sample_trace}. Data saved to {DATASET_FILE}.")